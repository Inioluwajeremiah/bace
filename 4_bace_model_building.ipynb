{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9844ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pytorch and keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d7ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd7e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac51db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af79a32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 215)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bace_data_mordred = pd.read_csv('combined_bace_inhibitors_ki_and_rdkit_descriptors.csv')\n",
    "bace_data_mordred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16dfa988",
   "metadata": {},
   "outputs": [],
   "source": [
    "bace_unscaled = bace_data_mordred[['Ki (nM)']]\n",
    "bace_unscaled.to_csv('bace_ki_unscaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c8cf2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 209)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = bace_data_mordred.drop(['BindingDB Reactant_set_id', 'Ligand SMILES', 'BindingDB MonomerID', 'BindingDB Ligand Name', 'Target Name', 'Ki (nM)'], axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f97a575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>349.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "count 349.00\n",
       "mean    0.01\n",
       "std     0.06\n",
       "min     0.00\n",
       "25%     0.00\n",
       "50%     0.00\n",
       "75%     0.01\n",
       "max     1.00"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get bace scaled ki \n",
    "bace_ki = pd.read_csv('bace_ki_minmax_scale.csv')\n",
    "bace_ki.describe()\n",
    "\n",
    "# bace_ki = pd.read_csv('bace_ki_values_log_transformation.csv')\n",
    "# bace_ki.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbcff4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-2.22</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-1.11</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>3.40</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-1.14</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.79</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows × 209 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8    9    ...   199  \\\n",
       "0    0.35  0.35  1.18  1.50 -1.47  1.10  1.19  1.09  0.77 0.00  ... -0.18   \n",
       "1    0.35  0.35  1.18  1.50 -1.47  1.10  1.19  1.09  0.77 0.00  ... -0.18   \n",
       "2    0.32  0.32  1.98  1.54 -2.22  1.11  1.19  1.11  1.21 0.00  ... -0.18   \n",
       "3    0.45  0.45  0.92  0.01 -1.92  1.71  1.81  1.71  1.01 0.00  ... -0.18   \n",
       "4    0.35  0.35  1.18  1.50 -1.47  1.10  1.19  1.09  0.77 0.00  ... -0.18   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  ...  ...   ...   \n",
       "344 -1.11 -1.11  0.37 -0.13  0.45 -0.21 -0.30 -0.21  0.12 0.00  ... -0.18   \n",
       "345  0.94  0.94  3.40 -0.90 -0.28 -0.74 -0.79 -0.74 -0.40 0.00  ... -0.18   \n",
       "346  0.29  0.29  0.95 -0.35 -1.04 -0.37 -0.35 -0.36 -0.12 0.00  ... -0.18   \n",
       "347 -1.14 -1.14 -0.39 -0.07  0.95  0.07  0.09  0.07 -0.48 0.00  ... -0.18   \n",
       "348  0.93  0.93  3.79 -0.81 -0.34 -0.52 -0.55 -0.52 -0.20 0.00  ... -0.18   \n",
       "\n",
       "     200  201   202  203   204  205   206  207  208  \n",
       "0   0.00 0.00 -0.05 0.00 -0.44 0.00 -0.22 0.00 0.00  \n",
       "1   0.00 0.00 -0.05 0.00 -0.44 0.00 -0.22 0.00 0.00  \n",
       "2   0.00 0.00 -0.05 0.00 -0.44 0.00 -0.22 0.00 0.00  \n",
       "3   0.00 0.00 -0.05 0.00 -0.44 0.00 -0.22 0.00 0.00  \n",
       "4   0.00 0.00 -0.05 0.00 -0.44 0.00 -0.22 0.00 0.00  \n",
       "..   ...  ...   ...  ...   ...  ...   ...  ...  ...  \n",
       "344 0.00 0.00 -0.05 0.00 -0.44 0.00 -0.22 0.00 0.00  \n",
       "345 0.00 0.00 -0.05 0.00 -0.44 0.00 -0.22 0.00 0.00  \n",
       "346 0.00 0.00 -0.05 0.00 -0.44 0.00 -0.22 0.00 0.00  \n",
       "347 0.00 0.00 -0.05 0.00 -0.44 0.00 -0.22 0.00 0.00  \n",
       "348 0.00 0.00 -0.05 0.00 -0.44 0.00 -0.22 0.00 0.00  \n",
       "\n",
       "[349 rows x 209 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the data using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(X)\n",
    "pd.DataFrame(data_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a9ce6a",
   "metadata": {},
   "source": [
    "### Scale  Descriptors Using Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "66760090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Descriptors after Variance Thresholding:\n",
      "170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(349, 170)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "descriptor_names= column_names = X.columns.tolist()\n",
    "\n",
    "# Initialize the VarianceThreshold object with your chosen threshold (e.g., 0.01)\n",
    "variance_threshold = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "# Fit and transform the data using variance thresholding\n",
    "data_selected = variance_threshold.fit_transform(data_normalized)\n",
    "\n",
    "# Get the indices of the selected descriptors\n",
    "selected_indices = variance_threshold.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected descriptors\n",
    "selected_descriptors = X.columns[selected_indices]\n",
    "\n",
    "# Print the selected descriptors\n",
    "print(\"Selected Descriptors after Variance Thresholding:\")\n",
    "print(len(selected_descriptors))\n",
    "data_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "40828671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 209)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "62a682e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 170)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96e1c6",
   "metadata": {},
   "source": [
    "### Scale Descriptors Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af2b6dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio of Principal Components:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize the PCA object with the number of principal components you want to retain (e.g., 2)\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "# Fit and transform the data using PCA\n",
    "data_pca = pca.fit_transform(data_normalized)\n",
    "\n",
    "# Optionally, you can also access the explained variance ratio for each principal component\n",
    "explained_variance_ratios = pca.explained_variance_ratio_\n",
    "print(\"Explained Variance Ratio of Principal Components:\")\n",
    "print(len(explained_variance_ratios))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97beeb1f",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "11037ea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 23ms/step - loss: 6.4522 - val_loss: 2.5153\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 3.5979 - val_loss: 2.1842\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.8621 - val_loss: 2.0904\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.5488 - val_loss: 2.1705\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.3467 - val_loss: 2.1673\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 2.0921 - val_loss: 2.2225\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.0084 - val_loss: 2.3233\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.8720 - val_loss: 2.3216\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.8179 - val_loss: 2.5009\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.8732 - val_loss: 2.5114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f05beba2f0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing your data can be crucial for deep learning models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape the input for CNN and RNN\n",
    "# CNN expects a 3D input (samples, timesteps, features)\n",
    "X_cnn = data_selected.reshape(data_selected.shape[0], data_selected.shape[1], 1)\n",
    "# X_cnn = data_normalized.reshape(data_normalized.shape[0], data_normalized.shape[1], 1)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_cnn_train, X_cnn_test, y_train, y_test = train_test_split(data_normalized, bace_ki, test_size=0.2, random_state=119)\n",
    "# X_rnn_train, X_rnn_test = X_rnn[y_train.index], X_rnn[y_test.index]\n",
    "\n",
    "# Define the CNN model\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv1D(32, 2, activation='relu', input_shape=X_cnn_train.shape[1:]))\n",
    "model_cnn.add(MaxPooling1D(2))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(32, activation='relu'))\n",
    "model_cnn.add(Dense(1))\n",
    "\n",
    "# Compile the CNN model\n",
    "model_cnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the CNN model\n",
    "model_cnn.fit(X_cnn_train, y_train, epochs=10, batch_size=32, validation_data=(X_cnn_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45135639",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e8336163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 29ms/step - loss: 13.6813 - val_loss: 11.9297\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 11.2294 - val_loss: 9.6837\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 8.7591 - val_loss: 7.5735\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 6.5531 - val_loss: 5.8105\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 5.0136 - val_loss: 4.7978\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 4.0677 - val_loss: 4.4204\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 3.3521 - val_loss: 4.4179\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2.9139 - val_loss: 4.2747\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2.5958 - val_loss: 4.2322\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 2.3474 - val_loss: 3.9150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f05e252500>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM\n",
    "\n",
    "# RNN/LSTM expects a 3D input (samples, timesteps, features)\n",
    "# X_rnn = data_selected.reshape(data_selected.shape[0], 1, data_selected.shape[1])\n",
    "X_rnn = data_normalized.reshape(data_normalized.shape[0],1, data_normalized.shape[1])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_rnn_train, X_rnn_test = X_rnn[y_train.index], X_rnn[y_test.index]\n",
    "\n",
    "# Define the RNN model\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(LSTM(32, activation='relu', input_shape=X_rnn_train.shape[1:]))\n",
    "model_rnn.add(Dense(1))\n",
    "\n",
    "# Compile the RNN model\n",
    "model_rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the RNN model\n",
    "model_rnn.fit(X_rnn_train, y_train, epochs=10, batch_size=32, validation_data=(X_rnn_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df3dc4",
   "metadata": {},
   "source": [
    "### Evaluate CNN and RNN performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "41a79be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "CNN Model:\n",
      "MSE: 2.51\n",
      "MAE: 1.30\n",
      "RMSE: 1.58\n",
      "R-squared: 0.37\n",
      "\n",
      "RNN Model:\n",
      "MSE: 3.91\n",
      "MAE: 1.41\n",
      "RMSE: 1.98\n",
      "R-squared: 0.02\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Make predictions using the CNN model\n",
    "y_pred_cnn = model_cnn.predict(X_cnn_test)\n",
    "\n",
    "# Make predictions using the RNN model\n",
    "y_pred_rnn = model_rnn.predict(X_rnn_test)\n",
    "\n",
    "# Calculate evaluation metrics for the CNN model\n",
    "mse_cnn = mean_squared_error(y_test, y_pred_cnn)\n",
    "mae_cnn = mean_absolute_error(y_test, y_pred_cnn)\n",
    "rmse_cnn = np.sqrt(mse_cnn)\n",
    "r2_cnn = r2_score(y_test, y_pred_cnn)\n",
    "\n",
    "# Calculate evaluation metrics for the RNN model\n",
    "mse_rnn = mean_squared_error(y_test, y_pred_rnn)\n",
    "mae_rnn = mean_absolute_error(y_test, y_pred_rnn)\n",
    "rmse_rnn = np.sqrt(mse_rnn)\n",
    "r2_rnn = r2_score(y_test, y_pred_rnn)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"CNN Model:\")\n",
    "print(f\"MSE: {mse_cnn:.2f}\")\n",
    "print(f\"MAE: {mae_cnn:.2f}\")\n",
    "print(f\"RMSE: {rmse_cnn:.2f}\")\n",
    "print(f\"R-squared: {r2_cnn:.2f}\")\n",
    "\n",
    "print(\"\\nRNN Model:\")\n",
    "print(f\"MSE: {mse_rnn:.2f}\")\n",
    "print(f\"MAE: {mae_rnn:.2f}\")\n",
    "print(f\"RMSE: {rmse_rnn:.2f}\")\n",
    "print(f\"R-squared: {r2_rnn:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ac1d5",
   "metadata": {},
   "source": [
    "### Scale X using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b918102",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ee84074e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions using the CNN model\n",
    "y_pred_cnn = model_cnn.predict(X_cnn_test)\n",
    "\n",
    "# Make predictions using the RNN model\n",
    "y_pred_rnn = model_rnn.predict(X_rnn_test)\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Scatter plot for CNN model\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_cnn, color='b', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)\n",
    "plt.xlabel('Actual Target')\n",
    "plt.ylabel('Predicted Target (CNN)')\n",
    "plt.title('CNN Model')\n",
    "\n",
    "# Scatter plot for RNN model\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_rnn, color='r', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2)\n",
    "plt.xlabel('Actual Target')\n",
    "plt.ylabel('Predicted Target (RNN)')\n",
    "plt.title('RNN Model')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03579941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "479c88be",
   "metadata": {},
   "source": [
    "### Ensemble ML Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "babd4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_selected, bace_ki ,test_size=0.2, random_state = 117)\n",
    "# 117\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8a564486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2score => -0.7172539433907523 \n",
      " rmse => 0.052191803638434814\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "r2score = r2_score(y_test, y_predict)\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "print(f\"r2score => {r2score} \\n rmse => {rmse}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c5dbce",
   "metadata": {},
   "source": [
    "### Using LazyPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1d6082f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:43<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6019\n",
      "[LightGBM] [Info] Number of data points in the train set: 279, number of used features: 135\n",
      "[LightGBM] [Info] Start training from score 0.010838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QuantileRegressor</th>\n",
       "      <td>52043352730642538558128565894906166112593830493...</td>\n",
       "      <td>-7617940037383907576006144740888837782831452580...</td>\n",
       "      <td>34761925077571202570374276903608045475742208169...</td>\n",
       "      <td>27.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>27115338339240238026509447221698479951671489183...</td>\n",
       "      <td>-3969056771396034285658893847340331073484733504...</td>\n",
       "      <td>25091619881245573588839301120.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>584584769268139616632832.00</td>\n",
       "      <td>-855696546320030367744000.00</td>\n",
       "      <td>36842147234.09</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>584584769268139616632832.00</td>\n",
       "      <td>-855696546320030367744000.00</td>\n",
       "      <td>36842147234.09</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>606382232964626.75</td>\n",
       "      <td>-887602978687349.75</td>\n",
       "      <td>1186572.88</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>1589.09</td>\n",
       "      <td>-2323.60</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>53.40</td>\n",
       "      <td>-75.70</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>10.09</td>\n",
       "      <td>-12.31</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>5.62</td>\n",
       "      <td>-5.76</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>3.68</td>\n",
       "      <td>-2.93</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>3.59</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>3.43</td>\n",
       "      <td>-2.55</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>3.33</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>3.33</td>\n",
       "      <td>-2.41</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>2.09</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>1.85</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>1.74</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>1.73</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>1.69</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>1.68</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>1.68</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.68</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>1.68</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>1.68</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>1.68</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>1.68</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>1.67</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>1.63</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>1.57</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>1.50</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>1.47</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>1.46</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>1.44</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>1.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>1.39</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>1.39</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>1.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>1.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>1.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Adjusted R-Squared  \\\n",
       "Model                                                                              \n",
       "QuantileRegressor             52043352730642538558128565894906166112593830493...   \n",
       "Lars                          27115338339240238026509447221698479951671489183...   \n",
       "TransformedTargetRegressor                           584584769268139616632832.00   \n",
       "LinearRegression                                     584584769268139616632832.00   \n",
       "RANSACRegressor                                               606382232964626.75   \n",
       "SGDRegressor                                                             1589.09   \n",
       "MLPRegressor                                                               53.40   \n",
       "ExtraTreeRegressor                                                         10.09   \n",
       "PassiveAggressiveRegressor                                                  5.62   \n",
       "LinearSVR                                                                   3.68   \n",
       "SVR                                                                         3.59   \n",
       "BaggingRegressor                                                            3.43   \n",
       "KernelRidge                                                                 3.33   \n",
       "Ridge                                                                       3.33   \n",
       "RandomForestRegressor                                                       2.09   \n",
       "GradientBoostingRegressor                                                   1.85   \n",
       "GaussianProcessRegressor                                                    1.75   \n",
       "ExtraTreesRegressor                                                         1.75   \n",
       "OrthogonalMatchingPursuit                                                   1.74   \n",
       "HuberRegressor                                                              1.73   \n",
       "RidgeCV                                                                     1.69   \n",
       "LassoLarsCV                                                                 1.68   \n",
       "LassoLars                                                                   1.68   \n",
       "Lasso                                                                       1.68   \n",
       "ElasticNetCV                                                                1.68   \n",
       "ElasticNet                                                                  1.68   \n",
       "DummyRegressor                                                              1.68   \n",
       "LassoCV                                                                     1.68   \n",
       "PoissonRegressor                                                            1.67   \n",
       "BayesianRidge                                                               1.63   \n",
       "OrthogonalMatchingPursuitCV                                                 1.57   \n",
       "LarsCV                                                                      1.50   \n",
       "LassoLarsIC                                                                 1.47   \n",
       "TweedieRegressor                                                            1.46   \n",
       "NuSVR                                                                       1.44   \n",
       "KNeighborsRegressor                                                         1.42   \n",
       "DecisionTreeRegressor                                                       1.39   \n",
       "AdaBoostRegressor                                                           1.39   \n",
       "LGBMRegressor                                                               1.37   \n",
       "HistGradientBoostingRegressor                                               1.37   \n",
       "XGBRegressor                                                                1.25   \n",
       "\n",
       "                                                                       R-Squared  \\\n",
       "Model                                                                              \n",
       "QuantileRegressor             -7617940037383907576006144740888837782831452580...   \n",
       "Lars                          -3969056771396034285658893847340331073484733504...   \n",
       "TransformedTargetRegressor                          -855696546320030367744000.00   \n",
       "LinearRegression                                    -855696546320030367744000.00   \n",
       "RANSACRegressor                                              -887602978687349.75   \n",
       "SGDRegressor                                                            -2323.60   \n",
       "MLPRegressor                                                              -75.70   \n",
       "ExtraTreeRegressor                                                        -12.31   \n",
       "PassiveAggressiveRegressor                                                 -5.76   \n",
       "LinearSVR                                                                  -2.93   \n",
       "SVR                                                                        -2.79   \n",
       "BaggingRegressor                                                           -2.55   \n",
       "KernelRidge                                                                -2.42   \n",
       "Ridge                                                                      -2.41   \n",
       "RandomForestRegressor                                                      -0.60   \n",
       "GradientBoostingRegressor                                                  -0.24   \n",
       "GaussianProcessRegressor                                                   -0.10   \n",
       "ExtraTreesRegressor                                                        -0.10   \n",
       "OrthogonalMatchingPursuit                                                  -0.09   \n",
       "HuberRegressor                                                             -0.06   \n",
       "RidgeCV                                                                    -0.00   \n",
       "LassoLarsCV                                                                -0.00   \n",
       "LassoLars                                                                  -0.00   \n",
       "Lasso                                                                      -0.00   \n",
       "ElasticNetCV                                                               -0.00   \n",
       "ElasticNet                                                                 -0.00   \n",
       "DummyRegressor                                                             -0.00   \n",
       "LassoCV                                                                    -0.00   \n",
       "PoissonRegressor                                                            0.02   \n",
       "BayesianRidge                                                               0.08   \n",
       "OrthogonalMatchingPursuitCV                                                 0.16   \n",
       "LarsCV                                                                      0.27   \n",
       "LassoLarsIC                                                                 0.32   \n",
       "TweedieRegressor                                                            0.33   \n",
       "NuSVR                                                                       0.36   \n",
       "KNeighborsRegressor                                                         0.38   \n",
       "DecisionTreeRegressor                                                       0.43   \n",
       "AdaBoostRegressor                                                           0.43   \n",
       "LGBMRegressor                                                               0.46   \n",
       "HistGradientBoostingRegressor                                               0.46   \n",
       "XGBRegressor                                                                0.63   \n",
       "\n",
       "                                                                            RMSE  \\\n",
       "Model                                                                              \n",
       "QuantileRegressor             34761925077571202570374276903608045475742208169...   \n",
       "Lars                                            25091619881245573588839301120.00   \n",
       "TransformedTargetRegressor                                        36842147234.09   \n",
       "LinearRegression                                                  36842147234.09   \n",
       "RANSACRegressor                                                       1186572.88   \n",
       "SGDRegressor                                                                1.92   \n",
       "MLPRegressor                                                                0.35   \n",
       "ExtraTreeRegressor                                                          0.15   \n",
       "PassiveAggressiveRegressor                                                  0.10   \n",
       "LinearSVR                                                                   0.08   \n",
       "SVR                                                                         0.08   \n",
       "BaggingRegressor                                                            0.08   \n",
       "KernelRidge                                                                 0.07   \n",
       "Ridge                                                                       0.07   \n",
       "RandomForestRegressor                                                       0.05   \n",
       "GradientBoostingRegressor                                                   0.04   \n",
       "GaussianProcessRegressor                                                    0.04   \n",
       "ExtraTreesRegressor                                                         0.04   \n",
       "OrthogonalMatchingPursuit                                                   0.04   \n",
       "HuberRegressor                                                              0.04   \n",
       "RidgeCV                                                                     0.04   \n",
       "LassoLarsCV                                                                 0.04   \n",
       "LassoLars                                                                   0.04   \n",
       "Lasso                                                                       0.04   \n",
       "ElasticNetCV                                                                0.04   \n",
       "ElasticNet                                                                  0.04   \n",
       "DummyRegressor                                                              0.04   \n",
       "LassoCV                                                                     0.04   \n",
       "PoissonRegressor                                                            0.04   \n",
       "BayesianRidge                                                               0.04   \n",
       "OrthogonalMatchingPursuitCV                                                 0.04   \n",
       "LarsCV                                                                      0.03   \n",
       "LassoLarsIC                                                                 0.03   \n",
       "TweedieRegressor                                                            0.03   \n",
       "NuSVR                                                                       0.03   \n",
       "KNeighborsRegressor                                                         0.03   \n",
       "DecisionTreeRegressor                                                       0.03   \n",
       "AdaBoostRegressor                                                           0.03   \n",
       "LGBMRegressor                                                               0.03   \n",
       "HistGradientBoostingRegressor                                               0.03   \n",
       "XGBRegressor                                                                0.02   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "QuantileRegressor                   27.75  \n",
       "Lars                                 0.05  \n",
       "TransformedTargetRegressor           0.02  \n",
       "LinearRegression                     0.03  \n",
       "RANSACRegressor                      0.49  \n",
       "SGDRegressor                         0.01  \n",
       "MLPRegressor                         0.13  \n",
       "ExtraTreeRegressor                   0.03  \n",
       "PassiveAggressiveRegressor           0.01  \n",
       "LinearSVR                            0.14  \n",
       "SVR                                  0.01  \n",
       "BaggingRegressor                     0.48  \n",
       "KernelRidge                          0.02  \n",
       "Ridge                                0.03  \n",
       "RandomForestRegressor                4.30  \n",
       "GradientBoostingRegressor            1.26  \n",
       "GaussianProcessRegressor             0.06  \n",
       "ExtraTreesRegressor                  1.19  \n",
       "OrthogonalMatchingPursuit            0.04  \n",
       "HuberRegressor                       0.06  \n",
       "RidgeCV                              0.03  \n",
       "LassoLarsCV                          0.08  \n",
       "LassoLars                            0.02  \n",
       "Lasso                                0.03  \n",
       "ElasticNetCV                         2.52  \n",
       "ElasticNet                           0.02  \n",
       "DummyRegressor                       0.02  \n",
       "LassoCV                              2.44  \n",
       "PoissonRegressor                     0.03  \n",
       "BayesianRidge                        0.05  \n",
       "OrthogonalMatchingPursuitCV          0.05  \n",
       "LarsCV                               0.38  \n",
       "LassoLarsIC                          0.06  \n",
       "TweedieRegressor                     0.02  \n",
       "NuSVR                                0.06  \n",
       "KNeighborsRegressor                  0.07  \n",
       "DecisionTreeRegressor                0.03  \n",
       "AdaBoostRegressor                    0.32  \n",
       "LGBMRegressor                        0.09  \n",
       "HistGradientBoostingRegressor        0.48  \n",
       "XGBRegressor                         0.11  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "#Initialize and run LazyRegressor\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print the list of models and their performance metrics\n",
    "models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b514cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.to_csv('bace_lazy_predict_ki_rdkit_top_5_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "49a5b663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>13369136540843211088594440305468109961448425408...</td>\n",
       "      <td>-2712578428576883124991003495553277572078782727...</td>\n",
       "      <td>1039542198955073900248056276377927680.00</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>741414518383145648128.00</td>\n",
       "      <td>-1504319312661454782464.00</td>\n",
       "      <td>77414263671.79</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>4366316882397472256.00</td>\n",
       "      <td>-8859193674429652992.00</td>\n",
       "      <td>5940842924.91</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>4366316882397472256.00</td>\n",
       "      <td>-8859193674429652992.00</td>\n",
       "      <td>5940842924.91</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>10459.58</td>\n",
       "      <td>-21219.30</td>\n",
       "      <td>290.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>2.69</td>\n",
       "      <td>-2.44</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>2.65</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>2.58</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>2.11</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>2.08</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>1.92</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>2.72</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>1.58</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileRegressor</th>\n",
       "      <td>1.50</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.49</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>1.49</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>1.49</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>1.44</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>1.44</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>1.42</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>1.38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>1.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>1.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>1.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>1.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>1.31</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.59</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>1.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>1.26</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>1.26</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>1.26</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>1.24</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>1.23</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>1.23</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>1.21</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>1.19</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>1.16</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>1.14</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Adjusted R-Squared  \\\n",
       "Model                                                                              \n",
       "Lars                          13369136540843211088594440305468109961448425408...   \n",
       "RANSACRegressor                                         741414518383145648128.00   \n",
       "TransformedTargetRegressor                                4366316882397472256.00   \n",
       "LinearRegression                                          4366316882397472256.00   \n",
       "SGDRegressor                                                            10459.58   \n",
       "PassiveAggressiveRegressor                                                  2.69   \n",
       "KernelRidge                                                                 2.65   \n",
       "GaussianProcessRegressor                                                    2.58   \n",
       "LinearSVR                                                                   2.11   \n",
       "HuberRegressor                                                              2.08   \n",
       "Ridge                                                                       1.92   \n",
       "RidgeCV                                                                     1.58   \n",
       "QuantileRegressor                                                           1.50   \n",
       "Lasso                                                                       1.49   \n",
       "LassoLars                                                                   1.49   \n",
       "DummyRegressor                                                              1.49   \n",
       "OrthogonalMatchingPursuit                                                   1.44   \n",
       "ElasticNet                                                                  1.44   \n",
       "OrthogonalMatchingPursuitCV                                                 1.42   \n",
       "ElasticNetCV                                                                1.38   \n",
       "LassoLarsIC                                                                 1.33   \n",
       "LassoLarsCV                                                                 1.33   \n",
       "BayesianRidge                                                               1.33   \n",
       "LarsCV                                                                      1.32   \n",
       "LassoCV                                                                     1.31   \n",
       "DecisionTreeRegressor                                                       1.28   \n",
       "SVR                                                                         1.26   \n",
       "NuSVR                                                                       1.26   \n",
       "TweedieRegressor                                                            1.26   \n",
       "HistGradientBoostingRegressor                                               1.24   \n",
       "ExtraTreeRegressor                                                          1.23   \n",
       "BaggingRegressor                                                            1.23   \n",
       "AdaBoostRegressor                                                           1.22   \n",
       "XGBRegressor                                                                1.22   \n",
       "LGBMRegressor                                                               1.22   \n",
       "KNeighborsRegressor                                                         1.22   \n",
       "GradientBoostingRegressor                                                   1.21   \n",
       "RandomForestRegressor                                                       1.19   \n",
       "MLPRegressor                                                                1.16   \n",
       "ExtraTreesRegressor                                                         1.14   \n",
       "\n",
       "                                                                       R-Squared  \\\n",
       "Model                                                                              \n",
       "Lars                          -2712578428576883124991003495553277572078782727...   \n",
       "RANSACRegressor                                       -1504319312661454782464.00   \n",
       "TransformedTargetRegressor                               -8859193674429652992.00   \n",
       "LinearRegression                                         -8859193674429652992.00   \n",
       "SGDRegressor                                                           -21219.30   \n",
       "PassiveAggressiveRegressor                                                 -2.44   \n",
       "KernelRidge                                                                -2.34   \n",
       "GaussianProcessRegressor                                                   -2.21   \n",
       "LinearSVR                                                                  -1.24   \n",
       "HuberRegressor                                                             -1.19   \n",
       "Ridge                                                                      -0.86   \n",
       "RidgeCV                                                                    -0.18   \n",
       "QuantileRegressor                                                          -0.01   \n",
       "Lasso                                                                      -0.00   \n",
       "LassoLars                                                                  -0.00   \n",
       "DummyRegressor                                                             -0.00   \n",
       "OrthogonalMatchingPursuit                                                   0.10   \n",
       "ElasticNet                                                                  0.12   \n",
       "OrthogonalMatchingPursuitCV                                                 0.15   \n",
       "ElasticNetCV                                                                0.24   \n",
       "LassoLarsIC                                                                 0.33   \n",
       "LassoLarsCV                                                                 0.33   \n",
       "BayesianRidge                                                               0.33   \n",
       "LarsCV                                                                      0.36   \n",
       "LassoCV                                                                     0.37   \n",
       "DecisionTreeRegressor                                                       0.44   \n",
       "SVR                                                                         0.47   \n",
       "NuSVR                                                                       0.47   \n",
       "TweedieRegressor                                                            0.48   \n",
       "HistGradientBoostingRegressor                                               0.51   \n",
       "ExtraTreeRegressor                                                          0.54   \n",
       "BaggingRegressor                                                            0.54   \n",
       "AdaBoostRegressor                                                           0.55   \n",
       "XGBRegressor                                                                0.56   \n",
       "LGBMRegressor                                                               0.56   \n",
       "KNeighborsRegressor                                                         0.56   \n",
       "GradientBoostingRegressor                                                   0.58   \n",
       "RandomForestRegressor                                                       0.61   \n",
       "MLPRegressor                                                                0.67   \n",
       "ExtraTreesRegressor                                                         0.72   \n",
       "\n",
       "                                                                  RMSE  \\\n",
       "Model                                                                    \n",
       "Lars                          1039542198955073900248056276377927680.00   \n",
       "RANSACRegressor                                         77414263671.79   \n",
       "TransformedTargetRegressor                               5940842924.91   \n",
       "LinearRegression                                         5940842924.91   \n",
       "SGDRegressor                                                    290.75   \n",
       "PassiveAggressiveRegressor                                        3.70   \n",
       "KernelRidge                                                       3.65   \n",
       "GaussianProcessRegressor                                          3.58   \n",
       "LinearSVR                                                         2.99   \n",
       "HuberRegressor                                                    2.95   \n",
       "Ridge                                                             2.72   \n",
       "RidgeCV                                                           2.17   \n",
       "QuantileRegressor                                                 2.00   \n",
       "Lasso                                                             2.00   \n",
       "LassoLars                                                         2.00   \n",
       "DummyRegressor                                                    2.00   \n",
       "OrthogonalMatchingPursuit                                         1.89   \n",
       "ElasticNet                                                        1.88   \n",
       "OrthogonalMatchingPursuitCV                                       1.84   \n",
       "ElasticNetCV                                                      1.75   \n",
       "LassoLarsIC                                                       1.64   \n",
       "LassoLarsCV                                                       1.64   \n",
       "BayesianRidge                                                     1.64   \n",
       "LarsCV                                                            1.60   \n",
       "LassoCV                                                           1.59   \n",
       "DecisionTreeRegressor                                             1.49   \n",
       "SVR                                                               1.46   \n",
       "NuSVR                                                             1.45   \n",
       "TweedieRegressor                                                  1.44   \n",
       "HistGradientBoostingRegressor                                     1.40   \n",
       "ExtraTreeRegressor                                                1.36   \n",
       "BaggingRegressor                                                  1.35   \n",
       "AdaBoostRegressor                                                 1.34   \n",
       "XGBRegressor                                                      1.33   \n",
       "LGBMRegressor                                                     1.33   \n",
       "KNeighborsRegressor                                               1.32   \n",
       "GradientBoostingRegressor                                         1.29   \n",
       "RandomForestRegressor                                             1.25   \n",
       "MLPRegressor                                                      1.14   \n",
       "ExtraTreesRegressor                                               1.06   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "Lars                                 0.06  \n",
       "RANSACRegressor                      0.52  \n",
       "TransformedTargetRegressor           0.03  \n",
       "LinearRegression                     0.04  \n",
       "SGDRegressor                         0.00  \n",
       "PassiveAggressiveRegressor           0.02  \n",
       "KernelRidge                          0.02  \n",
       "GaussianProcessRegressor             0.04  \n",
       "LinearSVR                            0.14  \n",
       "HuberRegressor                       0.06  \n",
       "Ridge                                0.02  \n",
       "RidgeCV                              0.02  \n",
       "QuantileRegressor                    0.42  \n",
       "Lasso                                0.01  \n",
       "LassoLars                            0.03  \n",
       "DummyRegressor                       0.02  \n",
       "OrthogonalMatchingPursuit            0.02  \n",
       "ElasticNet                           0.02  \n",
       "OrthogonalMatchingPursuitCV          0.04  \n",
       "ElasticNetCV                         2.00  \n",
       "LassoLarsIC                          0.03  \n",
       "LassoLarsCV                          0.04  \n",
       "BayesianRidge                        0.04  \n",
       "LarsCV                               0.26  \n",
       "LassoCV                              2.26  \n",
       "DecisionTreeRegressor                0.03  \n",
       "SVR                                  0.03  \n",
       "NuSVR                                0.02  \n",
       "TweedieRegressor                     0.03  \n",
       "HistGradientBoostingRegressor        0.86  \n",
       "ExtraTreeRegressor                   0.02  \n",
       "BaggingRegressor                     0.17  \n",
       "AdaBoostRegressor                    0.23  \n",
       "XGBRegressor                         0.21  \n",
       "LGBMRegressor                        0.09  \n",
       "KNeighborsRegressor                  0.06  \n",
       "GradientBoostingRegressor            0.82  \n",
       "RandomForestRegressor                1.70  \n",
       "MLPRegressor                         0.38  \n",
       "ExtraTreesRegressor                  0.66  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e56c212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
